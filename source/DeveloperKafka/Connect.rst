Kafka Connect
=================

**Kafka Connect** -- компонент **Apache Kafka** с открытым исходным кодом, является основой для подключения **Kafka** к внешним системам, таким как базы данных, хранилища key-value, поисковые индексы и файловые системы. С **Kafka Connect** можно использовать существующие реализации коннекторов для перемещения данных в сервис **Kafka** и из него:

+ *Source Connector* -- принимает базы данных и обновляет таблицы потоков для топиков **Kafka**. Также собирает метрики со всех серверов приложений в топики **Kafka**, делая данные доступными для потоковой обработки с низкой задержкой;

+ *Sink Connector* -- доставляет данные из топиков **Kafka** во вторичные индексы, такие как **Elasticsearch**, или в пакетные системы для автономного анализа, такие как **Hadoop**.

**Kafka Connect** ориентирован на потоковую передачу данных из сервиса **Kafka** и в него, что упрощает написание высококачественных, надежных и высокопроизводительных плагинов. Это также позволяет фреймворку давать гарантии, которые трудно достичь с помощью других структур. **Kafka Connect** является неотъемлемым компонентом конвейера **ETL** в сочетании с сервисом **Kafka** и потоковой обработкой.

**Kafka Connect** может работать либо как автономный процесс для выполнения заданий на одной машине (например, сбор журналов), либо как распределенный, масштабируемый, отказоустойчивый сервис, поддерживающий всю структуру. Это позволяет сократить масштаб до разработки, тестирования и небольших продуктовых развертываний с низким барьером для входа и низкими эксплуатационными накладными расходами, а также увеличить масштаб поддержки конвейера данных большой организации.

Основные преимущества использования **Kafka Connect**:

+ *Data Centric Pipeline* -- использование значимых абстракций данных для извлечения или передачи данных в **Kafka**;
+ *Flexibility and Scalability (гибкость и масштабируемость)* -- работа с потоковыми и пакетно-ориентированными системами на одном узле или масштабирование до сервиса по всей ширине организации;
+ *Reusability and Extensibility (повторное использование и расширяемость)* -- использование существующих коннекторов и возможность расширения их для адаптации к конкретным потребностям и сокращения времени на разработку.


Connectors & Tasks
--------------------

Копирование данных между сервисом **Kafka** и сторонней системой осуществляется посредством создаваемых пользователями инстансов *Kafka Connectors*. Коннекторы бывают двух видов: *SourceConnectors* -- импортируют данные из другой системы, и *SinkConnectors* -- экспортируют данные в другую систему. Например, *JDBCSourceConnector* импортирует реляционную базу данных в **Kafka**, а *HDFSSinkConnector* экспортирует содержимое топика **Kafka** в файлы **HDFS**.

Реализации класса Connector не выполняют копирование данных самостоятельно: их конфигурация описывает набор данных для копирования, и Connector отвечает за разбиение этого задания на набор задач -- Tasks, которые могут быть распределены между объектами **Kafka Connect**. Tasks также бывают двух видов: SourceTask и SinkTask. При необходимости реализация класса Connector может отслеживать изменения данных внешних систем и запрашивать реконфигурацию задачи.

С назначением данных, которые должны быть скопированы, каждая задача *Task* должна скопировать свое подмножество данных в сервис **Kafka** или из него. Данные, которые копирует коннектор, должны быть представлены как партиционированный поток, аналогично модели топика **Kafka**, 
где каждая партиция представляет собой упорядоченную последовательность записей со смещениями. Каждой задаче назначается подмножество разделов для обработки. Иногда это сопоставление очевидно: каждый файл в наборе файлов журнала можно считать разделом, каждая строка в файле - это запись, а смещения - это просто позиция в файле. В других случаях может потребоваться немного больше усилий для сопоставления с этой моделью: соединитель JDBC может сопоставить каждую таблицу с разделом, но смещение менее ясно. Одно из возможных сопоставлений использует столбец отметки времени для генерации запросов для постепенного возврата новых данных, и в качестве смещения может использоваться последняя запрашиваемая отметка времени.

С назначением данных, которые нужно скопировать, каждая задача должна скопировать свое подмножество данных в Кафку или из Кафки. Данные, которые копирует соединитель, должны быть представлены в виде секционированного потока, аналогичного модели раздела Кафки, где каждая секция представляет собой упорядоченную последовательность записей с смещениями. Каждой задаче назначается подмножество разделов для обработки. Иногда это сопоставление ясно: каждый файл в наборе файлов журнала можно считать разделом, каждая строка в файле является записью, а смещения-просто позицией в файле. В других случаях может потребоваться немного больше усилий для сопоставления с этой моделью: соединитель JDBC может сопоставлять каждую таблицу с секцией, но смещение менее ясно. Одно из возможных сопоставлений использует столбец timestamp для создания запросов для постепенного возврата новых данных, а последний запрошенный timestamp может использоваться в качестве смещения.

With an assignment of data to be copied in hand, each Task must copy its subset of the data to or from Kafka. The data that a connector copies must be represented as a partitioned stream, similar to the model of a Kafka topic, where each partition is an ordered sequence of records with offsets. Each task is assigned a subset of the partitions to process. Sometimes this mapping is clear: each file in a set of log files can be considered a partition, each line within a file is a record, and offsets are simply the position in the file. In other cases it may require a bit more effort to map to this model: a JDBC connector can map each table to a partition, but the offset is less clear. One possible mapping uses a timestamp column to generate queries to incrementally return new data, and the last queried timestamp can be used as the offset.





