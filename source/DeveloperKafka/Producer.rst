Kafka Java Producer
=====================

Платформа **ADS** включает в себя Java producer, поставляемый вместе с **Kafka**.

В документе представлен общий обзор работы поставщика, введение в параметры конфигурации для настройки и примеры из каждой клиентской библиотеки.


Концепция
-----------

Поставщик **Kafka** концептуально намного проще, чем потребитель, так как у него нет необходимости в групповой координации. Его основная функция состоит в том, чтобы сопоставить каждое сообщение с партицией топика и отправить запрос лидеру соответствующей партиции. Первое выполняется с помощью partitioner -- механизма, выбирающего партицию посредством хэш-функции, и гарантирующего, что все сообщения с одинаковым (непустым) ключом отправляются в одну и ту же партицию. Если ключ не указан, то партиция определяется циклически с целью обеспечения равномерного распределения по партициям топика.

В каждой партиции кластера **Kafka** есть лидер и набор реплик среди брокеров -- все записи проходят через лидера партиции, а реплики синхронизируются посредством выборки из него. Когда лидер отключается или выходит из строя, следующий лидер выбирается из числа синхронизированных реплик. В зависимости от того, как настроен поставщик, каждый запрос лидеру партиции может удерживаться до тех пор, пока реплики не одобрят запись. Это дает поставщику некий контроль над эксплуатацией сообщения при условии некоторой стоимости общей пропускной способности.

Сообщения, направленные лидеру партиции, не могут сразу считываться потребителями независимо от настроек подтверждения поставщика. Только когда все синхронизированные реплики подтверждают запись, сообщение считается зафиксированным, что делает его доступным для чтения. Такой подход гарантирует, что уже прочитанные сообщения не могут быть потеряны по причине сбоя брокера. Но это также подразумевает, что сообщения, подтвержденые только лидером (то есть *acks=1*), могут быть потеряны в случае, если лидер партиции терпит неудачу до момента копирования сообщений репликами. Тем не менее, в большинстве случаев на практике такой способ часто является разумным компромиссом для обеспечения жизнеспособности сообщений (durability), при этом не оказывая существенного влияния на пропускную способность.

Большая часть тонкостей вокруг поставщиков связана с достижением высокой пропускной способности с учетом пакетирования/сжатия и обеспечением гарантий доставки сообщений. Далее приведены наиболее распространенные параметры настройки поведения поставщиков.


Конфигурация
-------------

Полный список параметров конфигурации доступен в документе `Настройки платформы Arenadata Streaming <https://docs.arenadata.io/ads/Config/index.html>`_. Но некоторые из ключевых параметров и их влияние на поведение поставщиков описаны в текущей главе.


Базовая конфигурация (Core Configuration)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Для того, чтобы поставщик мог найти кластер **Kafka**, необходимо установить свойство *bootstrap.servers*. Так же, хотя это и не требуется обязательно, но всегда следует устанавливать *client.id*, поскольку это позволяет легко сопоставлять запросы в брокере со сделавшим их инстансом клиента. Данные настройки одинаковы для клиентов **Java**, **C/C++**, **Python**, **Go** и **.NET**.


Жизнеспособность сообщений (Message Durability)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Жизнеспособность сообщений, записанных в **Kafka**, можно контролировать с помощью параметра *acks*. Значение по умолчанию *1* требует от лидера партиции явного подтверждения об успешно выполненной записи. Самая сильная гарантия, которую предоставляет **Kafka** -- *acks=all* -- сообщение не только допущено к записи лидером партиции, но и успешно скопировано на все синхронизированные реплики. Можно также использовать значение *0* для максимизации пропускной способности, но тогда отсутствует гарантия успешной записи сообщения в журнал брокера, так как в этом случае брокер не отправляет ответ, что также означает невозможность определения смещение сообщения. Для клиентов **C/C++**, **Python**, **Go** и **.NET** это является конфигурацией для каждого отдельного топика, но ее можно применять глобально с помощью вложенной конфигурации *default_topic_conf* в **C/C++** и *default.topic.config* в **Python**, **Go** и **.NET**.



Порядок сообщений (Message Ordering)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Как правило, сообщения записываются в брокер в том же порядке, в котором они поступают от клиента поставщика. Однако если разрешить повторные попытки сообщений, установив для них значение больше *0* (*0* -- значение по умолчанию), может измениться их порядок, так как повтор возможен только после свершения успешной записи. Чтобы избежать переупорядочения, можно установить параметр *max.in.flight.requests.per.connection* в значение *1*, тогда брокеру одновременно может быть отправлен только один запрос. В случае без подключения повторных попыток сообщений брокер сохраняет порядок получаемых записей, но при этом могут быть пробелы из-за отдельных сбоев отправки.


Пакетирование и сжатие (Batching/Compression)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Поставщики **Kafka** пакетируют отправляемые сообщения для повышения пропускной способности. С клиентом **Java** можно управлять максимальным размером каждого пакета сообщений в параметре *batch.size*. Для большего времени на заполнение пакетов доступен параметр *linger.ms*, на значение которого поставщик задерживает отправку. Установкой *compression.type* включается сжатие, оно охватывает полные пакеты сообщений, поэтому большие пакеты обычно означают более высокую степень сжатия.

С клиентами **C/C++**, **Python**, **Go** и **.NET** для установки ограничения на количество сообщений в пакете используется *batch.num.messages*, сжатие включается с помощью *compression.codec*.


Ограничения очереди (Queuing Limits)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Ограничение общего объема доступной Java-клиенту памяти для сбора неотправленных сообщений контролируется параметром *buffer.memory*. При достижении установленного предела поставщик блокирует последующий набор записей до тех пор, пока *max.block.ms* не выводит исключение. Кроме того, чтобы избежать бесконечного хранения сообщений, можно установить тайм-аут в *request.timeout.ms*. Если это время ожидания истекает до того, как сообщение может быть успешно отправлено, то оно удаляется из очереди и генерируется исключение.

Клиенты **C/C++**, **Python**, **Go** и **.NET** имеют аналогичные настройки. Параметр *queue.buffering.max.messages* -- для ограничения общего количества сообщений, поставляемых в очередь в любой момент времени (для отчетов о передаче, повторных попытках или доставке). И параметр *queue.buffering.max.ms* -- для ограничения периода времени ожидания клиентом заполнения пакета перед отправкой брокеру.


Примеры
----------



