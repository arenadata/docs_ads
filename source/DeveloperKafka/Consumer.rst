Kafka Java Consumer
====================

Платформа **ADS** включает в себя Java consumer, поставляемый вместе с **Kafka**.

В документе представлен общий обзор работы потребителя, введение в параметры конфигурации для настройки и примеры из каждой клиентской библиотеки.


Концепция
------------

Consumer group -- группа потребителей, взаимодействующих для использования данных из топиков. Партиции в топиках делятся между потребителями в группе, и при изменениях в группе партиции перераспределяются таким образом, что каждый потребитель получает пропорциональную долю партиций. Такой процесс называется перебалансировкой группы (rebalancing the group).

Основное различие в управлении группами между старым "high-level" потребителем и новым заключается в том, что первый зависит от **ZooKeeper**, а второй использует групповой протокол, встроенный в саму **Kafka**. В данном протоколе один из брокеров назначается координатором группы и отвечает за управление ее потребителями и за назначение им партиций.

Координатор каждой группы выбирается из лидеров внутренних смещений *__consumer_offsets*. Обычно идентификатор группы хэшируется в одной из партиций топика, и лидер данной партиции выбирается в качестве координатора. Таким образом, управление группами потребителей разделяется примерно поровну между всеми брокерами в кластере, что позволяет масштабировать количество групп за счет увеличения числом брокеров.

Когда потребитель запускается, он находит координатора для своей группы и отправляет запрос на присоединение. При этом координатор начинает перебалансировку, что приводит к формированию новой группы.

Каждый участник в группе должен посылать heartbeat-сообщения координатору. В случае если до истечения настроенного тайм-аута сессии такового не получено, координатор исключает потребителя из группы и переназначает его партиции.

Управление смещением (Offset Management)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

После получения потребителем назначения от координатора необходимо выявить начальную позицию для каждой определенной партиции. Когда группа создается впервые, до того, как какие-либо сообщения были использованы, позиция устанавливается в соответствии с политикой сброса смещения (*auto.offset.reset*). Как правило, потребление начинается с самого раннего либо с самого позднего смещения.

Потребителю необходимо фиксировать свои смещения в партиции в соответствии с ходом прочтения сообщений. Поскольку, если потребитель выходит из строя или выключается, его партиции переназначаются другому участнику группы, который начинает потребление сообщений с последнего закоммиченного смещения. В случае аварийного завершения работы потребитиеля до того, как какое-либо его смещение зафиксировано, следующий потребитель использует политику сброса.

Политика фиксации смещения имеет ключевое значение для обеспечения необходимых приложению гарантий доставки сообщений. По умолчанию потребитель настроен на использование политики автоматического коммита, которая инициирует фиксацию с периодическим интервалом. Также потребителем поддерживается API, который можно использовать для ручного управления смещением. В примерах приведено несколько подробных случаев API-фиксации и обсуждение компромиссов с точки зрения производительности и надежности (`Примеры`_).

При записи во внешнюю систему позиция потребителя должна быть согласована с тем, что хранится в виде выходных данных. Именно поэтому потребитель хранит свое смещение в том же месте, где выходные данные. Например, Kafka Connect записывает данные в **HDFS** вместе со смещениями считываемых данных, что гарантирует обоюдное обновление данных и смещений. Аналогичная схема применяется для многих других систем данных, требующих более строгой семантики, и для которых сообщения не имеют первичного ключа для обеспечения дедупликации.

Так **Kafka** поддерживает обработку exactly-once в Kafka Streams, и поставщик или потребитель транзакций может использоваться для обеспечения доставки exactly-once при передаче и обработке данных между топиками **Kafka**. В противном случае **Kafka** гарантирует доставку at-least-once по умолчанию, но при этом можно реализовать доставку at-most-once, отключив повторные попытки для поставщика и зафиксировав смещения в потребителе перед обработкой пакета сообщений.


Конфигурация
-------------

Полный список параметров конфигурации доступен в документе `Настройки платформы Arenadata Streaming <https://docs.arenadata.io/ads/Config/index.html>`_. Но некоторые из ключевых параметров и их влияние на поведение потребителя описаны в текущей главе.

Базовая конфигурация (Core Configuration)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Единственная обязательная настройка -- это *bootstrap.servers*, но при этом должен быть установлен *client.id* для сопоставления запросов в брокере со сделавшим их инстансом клиента. Как правило, все потребители в одной группе используют один и тот же идентификатор клиента.

Конфигурация группы (Group Configuration)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Параметр *group.id* должен быть всегда настроен за исключением случаев, когда API используется просто по назначению и нет необходимости хранить смещения в **Kafka**.

Тайм-аутом сессии можно управлять в параметре *session.timeout.ms*. Значение по умолчанию установлено на *30 секунд*, но если приложению требуется больше времени для обработки сообщений, то для избежания чрезмерной перебалансировки значение параметра можно безопасно увеличить. Это в основном актуально при использовании Java consumer и обработке сообщений в одном потоке. В таком случае также можно регулировать параметр *max.poll.records* для настройки количества требуемых для обработки на каждой итерации цикла записей (более подрорбно вопрос рассмотрен в главе `Основные возможности`_). 

Основным недостатком применения долгого тайм-аута сессии является то, что координатору требуется больше времени для обнаружения сбоя инстанса потребителя, а это значит, что другому потребителю в группе требуется больше времени для передачи партиций. Но при этом в случае необходимости нормального выключения потребитель отправляет координатору явный запрос покинуть группу, который инициирует немедленную перебалансировку.

Другим параметром, влияющим на поведение перебалансировки, является *heartbeat.interval.ms*. Он контролирует, как часто потребитель должен отправлять heartbeats-сообщения координатору. Это также способ, когда необходимость перебалансировки определяется засчет потребителя, поэтому более короткий интервал heartbeats-сообщений обычно означает более быструю перебалансировку. Значение по умолчанию составляет *3 секунды*. Для больших групп целесообразно увеличить значение параметра.

Управление смещением (Offset Management)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Двумя основными параметрами, влияющими на управление смещением, являются автоматическая фиксация и политика сброса смещения. В первом случае при установленном по умолчанию параметре *enable.auto.commit* потребитель автоматически фиксирует смещения с заданным в *auto.commit.interval.ms* интервалом (по умолчанию -- *5 секунд*).

Второй параметр *auto.offset.reset* определяет поведение потребителя, когда нет зафиксированной позиции смещения (в случае, когда группа инициализируется впервые), или когда оно выходит за пределы диапазона. Можно установить сброс положения на самое раннее смещение -- *earliest*, либо на самое позднее -- *latest* (задано по умолчанию). Также можно выбрать значение *none* для самостоятельной установки начального смещения и ручной обработки ошибок вне диапазона.


Инициализация
---------------

Потребитель Java consumer создается с помощью стандартного файла свойств *Properties*:

  ::
  
   Properties config = new Properties();
   config.put("client.id", InetAddress.getLocalHost().getHostName());
   config.put("group.id", "foo");
   config.put("bootstrap.servers", "host1:9092,host2:9092");
   new KafkaConsumer<K, V>(config);

.. important:: Ошибки конфигурации приводят к возникновению исключения *KafkaException* из конструктора *KafkaConsumer*

Конфигурация **C/C++** (*librdkafka*) похожа, но при этом необходимо обрабатывать ошибки конфигурации непосредственно при настройке свойств:

  ::
  
   char hostname[128];
   char errstr[512];
   
   rd_kafka_conf_t *conf = rd_kafka_conf_new();
   
   if (gethostname(hostname, sizeof(hostname))) {
    fprintf(stderr, "%% Failed to lookup hostname\n");
    exit(1);
   }
   
   if (rd_kafka_conf_set(conf, "client.id", hostname,
                        errstr, sizeof(errstr)) != RD_KAFKA_CONF_OK) {
    fprintf(stderr, "%% %s\n", errstr);
    exit(1);
   }
   
   if (rd_kafka_conf_set(conf, "group.id", "foo",
                        errstr, sizeof(errstr)) != RD_KAFKA_CONF_OK) {
    fprintf(stderr, "%% %s\n", errstr);
    exit(1);
   }
   
   if (rd_kafka_conf_set(conf, "bootstrap.servers", "host1:9092,host2:9092",
                        errstr, sizeof(errstr)) != RD_KAFKA_CONF_OK) {
    fprintf(stderr, "%% %s\n", errstr);
    exit(1);
   }
   
   /* Create Kafka consumer handle */
   rd_kafka_t *rk;
   if (!(rk = rd_kafka_new(RD_KAFKA_CONSUMER, conf,
                          errstr, sizeof(errstr)))) {
    fprintf(stderr, "%% Failed to create new consumer: %s\n", errstr);
    exit(1);
   }


Клиент **Python** может быть настроен через словарь следующим образом:

  ::
  
   from confluent_kafka import Consumer
   
   conf = {'bootstrap.servers': "host1:9092,host2:9092",
           'group.id': "foo",
           'default.topic.config': {'auto.offset.reset': 'smallest'}}
   
   consumer = Consumer(conf)


Клиент **Go** использует объект *ConfigMap* для передачи конфигурации потребителю:

  ::
  
   import (
       "github.com/confluentinc/confluent-kafka-go/kafka"
   )
   
   consumer, err := kafka.NewConsumer(&kafka.ConfigMap{
        "bootstrap.servers":    "host1:9092,host2:9092",
        "group.id":             "foo",
        "default.topic.config": kafka.ConfigMap{"auto.offset.reset": "smallest"}})


В **C#** испольуется *Dictionary<string, object>*:

  ::
  
   using System.Collections.Generic;
   using Confluent.Kafka;
   
   ...
   
   var config = new Dictionary<string, object>
   {
       { "bootstrap.servers", "host1:9092,host2:9092" },
       { "group.id", "foo" },
       { "default.topic.config", new Dictionary<string, object>
           {
               { "auto.offset.reset", "smallest" }
           }
       }
   }
   
   using (var consumer = new Consumer<Null, string>(config, null, new StringDeserializer(Encoding.UTF8)))
   {
       ...
   }



Основные возможности
----------------------

Хотя Java-клиент и *librdkafka* имеют много общих опций конфигурации и базовых функций, они используют довольно разные подходы, когда дело доходит до их потоковой модели и работы с потребителями. Прежде чем углубляться в примеры, полезно разобраться в дизайне API каждого клиента.


Java Client
^^^^^^^^^^^^^

**Java Client** разработан вокруг цикла обработки событий под управляением *poll()* API. Конструкция мотивирована системными вызовами UNIX *select* и *poll*. Базовый цикл потребления с Java API обычно принимает следующую форму:

  ::
  
   while (running) {
     ConsumerRecords<K, V> records = consumer.poll(Long.MAX_VALUE);
     process(records); // application-specific processing
     consumer.commitSync();
   }

В Java consumer нет фонового потока. API зависит от вызовов *poll()* для управления всеми операциями ввода-вывода, включая:

+ Присоединение к группе потребителей и обработка перебалансировкой партиций;
+ Периодичная отправка heartbeats-сообщений;
+ Периодичная отправка зафиксированных смещений (при включенном автокоммите);
+ Отправка и получение запросов на выборку для назначенных партиций.

Такая однопоточная модель означает, что нельзя отправлять heartbeats-сообщения, пока приложение обрабатывает записи по вызову *poll()*. Это приводит к тому, что потребитель выпадает из группы, если цикл обработки событий завершается, либо если задержка в обработке записи приводит к истечению времени ожидания сессии до следующей итерации цикла. Так и было задумано. Одна из проблем, которую пытается решить **Java Client**, -- обеспечение жизнедеятельности потребителей в группе. В то время, пока потребителю назначены партиции, другие члены группы не могут их же использовать, поэтому важно убедиться, что каждый конкретный потребитель действительно прогрессирует.

Данная функция защищает приложение от большого класса сбоев, но недостатком является то, что необходима настройка времени ожидания сессии так, чтобы потребитель не превышал его в своей обычной обработке записей. Кроме этого параметр *max.poll.records* устанавливает верхнюю границу количества записей, возвращаемых при каждом вызове. Поэтому важно использовать *poll()* и *max.poll.records* с достаточно большим тайм-аутом сессии (например, от *30* до *60 секунд*) и ограничивать количество обработанных записей на каждой итерации.

В случае если данные параметры не настроены надлежащим образом, это, как правило, приводит к исключению *CommitFailedException* смещения для обработанных записей. При использовании политики автоматической фиксации, можно даже не заметить, когда это происходит, так как потребитель молча игнорирует сбои коммитов (если только это не происходит достаточно часто, чтобы повлиять на показатели задержки). Исключение можно перехватить и либо проигнорировать, либо выполнить необходимую логику отката:

  ::

   while (running) {
     ConsumerRecords<K, V> records = consumer.poll(Long.MAX_VALUE);
     process(records); // application-specific processing
     try {
       consumer.commitSync();
     } catch (CommitFailedException e) {
       // application-specific rollback of processed records
     }
   }


C/C++ Client (librdkafka)
^^^^^^^^^^^^^^^^^^^^^^^^^^^

*Librdkafka* использует многопоточный подход к потреблению **Kafka**. С точки зрения пользователя, взаимодействие с API не слишком отличается от примера, используемого Java-клиентом, когда пользователь вызывает *rd_kafka_consumer_poll* в цикле, хотя данный API возвращает только одно сообщение или событие за раз:

  ::
  
   while (running) {
    rd_kafka_message_t *rkmessage = rd_kafka_consumer_poll(rk, 500);
    if (rkmessage) {
      msg_process(rkmessage);
      rd_kafka_message_destroy(rkmessage);
   
      if ((++msg_count % MIN_COMMIT_COUNT) == 0)
        rd_kafka_commit(rk, NULL, 0);
    }
   }


В отличие от Java-клиента, *librdkafka* выполняет всю выборку и координирует взаимодействие в фоновых потоках, что освобождает от сложности настройки тайм-аута сессии в соответствии с ожидаемым временем обработки. Однако, поскольку фоновый поток поддерживает потребителя до тех пор, пока клиент не закроется, важно убедиться, что процесс не простаивает, так как в этом случае он продолжает удерживать назначенные ему партиции.

При этом перебалансировка партиций также происходит в фоновом потоке, а это говорит о том, что все равно приходится обрабатывать потенциальные ошибки коммита, поскольку потребитель может больше не иметь того же назначения партиций, когда начинается фиксация. Это не требуется при включенном автокоммите, так как при этом ошибки коммита игнорируются в автоматическом режиме, но это также означает, что нет возможности откатить обработку.

  ::
  
   while (running) {
     rd_kafka_message_t *rkmessage = rd_kafka_consumer_poll(rk, 1000);
     if (!rkmessage)
       continue; // timeout: no message
   
     msg_process(rkmessage); // application-specific processing
     rd_kafka_message_destroy(rkmessage);
   
     if ((++msg_count % MIN_COMMIT_COUNT) == 0) {
       rd_kafka_resp_err_t err = rd_kafka_commit(rk, NULL, 0);
       if (err) {
         // application-specific rollback of processed records
       }
     }
   }


Python, Go and .NET Clients
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Клиенты **Python**, **Go** и **.NET** на внутреннем уровне используют *librdkafka*, поэтому у них также применяется многопоточный подход к потреблению **Kafka**. С точки зрения пользователя, взаимодействие с API не слишком отличается от примера, используемого Java-клиентом, когда пользователь вызывает метод *poll()* в цикле, хотя данный API возвращает только одно сообщение за раз.

**Python**:

  ::
  
   try:
       msg_count = 0
       while running:
           msg = consumer.poll(timeout=1.0)
           if msg is None: continue
   
           msg_process(msg) # application-specific processing
           msg_count += 1
           if msg_count % MIN_COMMIT_COUNT == 0:
               consumer.commit(async=False)
   finally:
       # Shut down consumer
       consumer.close()


**Go**:

  ::
  
   for run == true {
       ev := consumer.Poll(0)
       switch e := ev.(type) {
       case *kafka.Message:
           // application-specific processing
       case kafka.Error:
           fmt.Fprintf(os.Stderr, "%% Error: %v\n", e)
           run = false
       default:
           fmt.Printf("Ignored %v\n", e)
       }
   }


Поведение потребителя **C#** аналогично, за исключением того, что перед входом в цикл *Poll* необходимо настроить обработчики для различных типов событий, что эффективно делается внутри метода *Poll* (важно обратить внимание, что весь код выполняется в том же потоке):

  ::
  
   consumer.OnMessage += (_, msg) =>
   {
       // handle message.
   }
   
   consumer.OnPartitionEOF += (_, end)
       => Console.WriteLine($"Reached end of topic {end.Topic} partition {end.Partition}.");
   
   consumer.OnError += (_, error)
   {
       Console.WriteLine($"Error: {error}");
       cancelled = true;
   }
   
   while (!cancelled)
   {
       consumer.Poll(TimeSpan.FromSeconds(1));
   }



Примеры
---------

Далее приведены подробные примеры использования consumer API с особым вниманием к управлению смещением и семантике доставки. 




